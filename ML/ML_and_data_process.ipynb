{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c27ecf-b8ec-4b63-a106-c2ae967ede3b",
   "metadata": {},
   "source": [
    "# Data processing for the data needed in the charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56ccf724-4919-42be-8702-cc28fb114b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47fce83-2014-4434-8acc-e055f57b54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('NewProcedure_Primary_CSV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6508870f-b8c1-46ae-a1a6-fe92bae7f587",
   "metadata": {},
   "source": [
    "## Extracting the data for the Country needed with 2 letter codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936b248b-8f50-45db-9f9a-37daea35d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"US\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe94171-b259-4542-aa50-8af75d6889da",
   "metadata": {},
   "source": [
    "### Collecting the data for OIL PRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d42fa7-5134-41ed-a03e-f519e35fc430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_data = data[(data['REF_AREA'] == code) & \n",
    "                     ((data['ENERGY_PRODUCT'] == 'CRUDEOIL') & (data['FLOW_BREAKDOWN'] == 'INDPROD')) & \n",
    "                     (data['UNIT_MEASURE'] == 'KBD')]\n",
    "\n",
    "# Select columns except for 'ASSESSMENT_CODE'\n",
    "columns_to_drop = ['ENERGY_PRODUCT', 'FLOW_BREAKDOWN', 'UNIT_MEASURE','ASSESSMENT_CODE']\n",
    "\n",
    "# Drop the specified columns\n",
    "filtered_data = filtered_data.drop(columns=columns_to_drop)\n",
    "filtered_data = filtered_data.rename(columns={'OBS_VALUE': 'PRODUCTION'})\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_data.to_csv(f\"PRODUCTION_{code}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1feb38c-9a43-4849-8585-5424fa82eecd",
   "metadata": {},
   "source": [
    "### Collecting the data for OIL EXPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49d73f3a-0392-418a-b3b2-9985c178939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data[(data['REF_AREA'] == code) & \n",
    "                     ((data['ENERGY_PRODUCT'] == 'CRUDEOIL') & (data['FLOW_BREAKDOWN'] == 'TOTEXPSB')) & \n",
    "                     (data['UNIT_MEASURE'] == 'KBD')]\n",
    "\n",
    "# Select columns except for 'ASSESSMENT_CODE'\n",
    "columns_to_drop = ['ENERGY_PRODUCT', 'FLOW_BREAKDOWN', 'UNIT_MEASURE','ASSESSMENT_CODE']\n",
    "\n",
    "# Drop the specified columns\n",
    "filtered_data = filtered_data.drop(columns=columns_to_drop)\n",
    "filtered_data = filtered_data.rename(columns={'OBS_VALUE': 'EXPORT'})\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_data.to_csv(f\"EXPORT_{code}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d126d8-f83b-4814-a32f-a639537cc99a",
   "metadata": {},
   "source": [
    "## Combining the EXPORT and PRODUCTION data for a country in a COUNTRY.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cee6350-028d-404c-b05d-0c94b102815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(f'PRODUCTION_{code}.csv')\n",
    "df2 = pd.read_csv(f'EXPORT_{code}.csv')\n",
    "\n",
    "# Extract the column you want to concatenate from the first DataFrame\n",
    "column_to_concat = df1['PRODUCTION']\n",
    "\n",
    "# Concatenate the column to the second DataFrame\n",
    "df2['PRODUCTION'] = column_to_concat\n",
    "\n",
    "# Save the modified second DataFrame to a new CSV file\n",
    "df2.to_csv(f'{code}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45dcca-d6e6-4407-bc5d-f9b058aa6ed5",
   "metadata": {},
   "source": [
    "## Coverting the data into JSON for easier use at the backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03e21939-94fc-4ae4-92d1-f8e098f76ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(f'{code}.csv')\n",
    "\n",
    "# Convert DataFrame to JSON\n",
    "json_data = df.to_json(orient='records')\n",
    "\n",
    "# Write JSON data to a file\n",
    "with open(f'{code}.json', 'w') as f:\n",
    "    f.write(json_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e12290c-6dcd-4342-93c8-7a5ed913ca4a",
   "metadata": {},
   "source": [
    "### comobining all the data for the biggest 4 exports grapghs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5610c19-66bb-4800-8b4a-d0ab78eb5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a DataFrame\n",
    "code = \"US\"\n",
    "df = pd.read_csv(f'{code}.csv')\n",
    "\n",
    "# Split the TIME_PERIOD column into year and month columns\n",
    "df[['year', 'month']] = df['TIME_PERIOD'].str.split('-', expand=True)\n",
    "\n",
    "# Drop the REF_AREA and PRODUCTION columns\n",
    "df = df.drop(columns=['REF_AREA', 'EXPORT','TIME_PERIOD'])\n",
    "df = df.rename(columns={'PRODUCTION': 'TARGET'})\n",
    "# Save the modified DataFrame back to a file\n",
    "df.to_csv(f\"{code}_processed2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73356ecd-c7d9-483d-b0ea-a48e633b1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('SA_processed2.csv')\n",
    "df2 = pd.read_csv('CA_processed2.csv')\n",
    "df3 = pd.read_csv('MX_processed2.csv')\n",
    "df4 = pd.read_csv('IQ_processed2.csv')\n",
    "\n",
    "df1 = df1.rename(columns={'TARGET': 'SA'})\n",
    "df1['CA'] = df2['TARGET']\n",
    "df1['MX'] = df3['TARGET']\n",
    "df1['IQ'] = df4['TARGET']\n",
    "filtered_data = df1[df1['year'] == 2023]\n",
    "df1 = df1.drop(columns=['year'])\n",
    "filtered_data.to_csv(f\"DATA2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b07bf97-c121-49ea-9edb-0aafe1111a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(f'DATA2.csv')\n",
    "\n",
    "# Convert DataFrame to JSON\n",
    "json_data = df.to_json(orient='records')\n",
    "\n",
    "# Write JSON data to a file\n",
    "with open(f'DATA2.json', 'w') as f:\n",
    "    f.write(json_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf0c5e7-4d5c-4ffa-9666-1976517fe9dd",
   "metadata": {},
   "source": [
    "# TRAINING THE ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd7568-3701-4e66-9a97-b6c59e915fca",
   "metadata": {},
   "source": [
    "### we got better results when we weighted the newes data with bigger coeficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f70837a-67ef-4bcd-ad54-47bdf4ae7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"SA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f485c17-c3e2-4394-855b-889e1a1ea44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 592674.4374702357\n",
      "R-squared Score: -0.005908907853198642\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# Read the data\n",
    "data = pd.read_csv(f'{code}_processed.csv')\n",
    "\n",
    "# Define X and y\n",
    "X = data[['month']]\n",
    "y = data['TARGET']\n",
    "\n",
    "# Define the weight coefficient 'a'\n",
    "a = 0.04\n",
    "# Assign weights to the data based on the year\n",
    "data['weight'] = 1 - (2024 - data['year']) * a\n",
    "\n",
    "# Instantiate the Random Forest model\n",
    "random_forest_model = RandomForestRegressor(n_estimators=100, max_depth=10, max_features=\"sqrt\", min_samples_leaf=4, min_samples_split=10, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest_model.fit(X_train, y_train, sample_weight=data.loc[X_train.index]['weight'])\n",
    "\n",
    "# Evaluate the model's performance\n",
    "y_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R-squared Score:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28024ba1-76ed-4d17-9766-218f33182ac3",
   "metadata": {},
   "source": [
    "## Saving the trained modes so it can be used in the backend for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f23bbbf-370f-462b-bc0a-1d6c892e2f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model_SA.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(random_forest_model, f'random_forest_model_{code}.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccaf86c-3240-4eee-bf02-1ca64f3f4d7d",
   "metadata": {},
   "source": [
    "#### making an example code so you can predict for a given mounth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29769b63-aa1b-47cc-832e-6bfcc1300b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7103.769704099567"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_mounth_you_would_like_to_predict = 3\n",
    "data_to_predict = pd.DataFrame({'month': [the_mounth_you_would_like_to_predict]})\n",
    "prediction = random_forest_model.predict(data_to_predict)\n",
    "float(prediction[0])\n",
    "# to return a float instead of an one element array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4e139-dd7b-4269-96b5-5299e51e35c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12c63b-8f31-4d46-b6e8-2342e124e7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
